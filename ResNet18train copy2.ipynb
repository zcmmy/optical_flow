{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from matplotlib_inline import backend_inline\n",
    "backend_inline.set_matplotlib_formats('svg')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anconda\\envs\\DL\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Anconda\\envs\\DL\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 2)\n",
    "model = model.to(device)\n",
    "\n",
    "epochs = 2\n",
    "learning_rate = 0.0005\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "creterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     18\u001b[0m     model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m trainloader:\n\u001b[0;32m     20\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     21\u001b[0m         labels \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32md:\\Anconda\\envs\\DL\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anconda\\envs\\DL\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:386\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anconda\\envs\\DL\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1039\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1032\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1039\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32md:\\Anconda\\envs\\DL\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anconda\\envs\\DL\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anconda\\envs\\DL\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anconda\\envs\\DL\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Anconda\\envs\\DL\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gen_train_test_data\n",
    "trainloader = gen_train_test_data.get_trainloader('data_train/')\n",
    "testloader = gen_train_test_data.get_testloader('data_test/')\n",
    "\n",
    "losses = []\n",
    "train_accuracies = []\n",
    "train_precisions = []\n",
    "train_recalls = []\n",
    "train_F1_scores = []\n",
    "test_accuracies = []\n",
    "test_precisions = []\n",
    "test_recalls = []\n",
    "test_F1_scores = []\n",
    "turns = c1 = c2 = 0\n",
    "tp = tn = fp = fn = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model = model.train()\n",
    "    for x, y in trainloader:\n",
    "        inputs = x.to(device)\n",
    "        labels = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = creterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        with torch.no_grad():\n",
    "            if (c1%100 == 0 and c1 != 0):\n",
    "                accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "                precision = tp/(tp+fp) if ((tp+fp)!=0) else 0\n",
    "                recall = tp/(tp+fn) if ((tp+fn)!=0) else 0\n",
    "                train_accuracies.append(accuracy)\n",
    "                train_precisions.append(precision)\n",
    "                train_recalls.append(recall)\n",
    "                train_F1_scores.append((2*precision*recall/(precision+recall)) if ((precision+recall)!=0) else 0)\n",
    "                tp = tn = fp = fn = 0\n",
    "            turns += 1\n",
    "            c1 += 10\n",
    "            _, predicted = torch.max(outputs.cpu(), dim=1)\n",
    "            labels = labels.cpu()\n",
    "            tp += torch.sum((labels.reshape(-1) == 0) & (predicted == 0)).item()\n",
    "            tn += torch.sum((labels.reshape(-1) == 1) & (predicted == 1)).item()\n",
    "            fp += torch.sum((labels.reshape(-1) == 1) & (predicted == 0)).item()\n",
    "            fn += torch.sum((labels.reshape(-1) == 0) & (predicted == 1)).item()\n",
    "            print(f'turns:{turns}, loss:{loss.item()}')\n",
    "\n",
    "    model = model.eval()\n",
    "    with torch.no_grad():\n",
    "        tp = tn = fp = fn = 0\n",
    "        for inputs, labels in testloader:\n",
    "            if (c2%100 == 0 and c2 != 0):\n",
    "                accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "                precision = tp/(tp+fp) if ((tp+fp)!=0) else 0\n",
    "                recall = tp/(tp+fn) if ((tp+fn)!=0) else 0\n",
    "                test_accuracies.append(accuracy)\n",
    "                test_precisions.append(precision)\n",
    "                test_recalls.append(recall)\n",
    "                test_F1_scores.append((2*precision*recall/(precision+recall)) if ((precision+recall)!=0) else 0)\n",
    "                tp = tn = fp = fn = 0\n",
    "            outputs = model(inputs.to(device))\n",
    "            _, predicted = torch.max(outputs.cpu(), dim=1)\n",
    "            labels = labels.cpu()\n",
    "            tp += torch.sum((labels.reshape(-1) == 0) & (predicted == 0)).item()\n",
    "            tn += torch.sum((labels.reshape(-1) == 1) & (predicted == 1)).item()\n",
    "            fp += torch.sum((labels.reshape(-1) == 1) & (predicted == 0)).item()\n",
    "            fn += torch.sum((labels.reshape(-1) == 0) & (predicted == 1)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(losses)), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = len(train_accuracies)+1\n",
    "plt.plot(range(1, lens), train_accuracies, color='red', linestyle='--', label='accuracies')\n",
    "plt.plot(range(1, lens), train_precisions, color='blue', linestyle='-.', label='precisions')\n",
    "plt.plot(range(1, lens), train_recalls, color='green', linestyle=':', label='recalls')\n",
    "plt.plot(range(1, lens), train_F1_scores, color='yellow', linestyle='-', label='F1_scores')\n",
    "plt.legend()\n",
    "\n",
    "print(f'训练集精度: {100*train_accuracies[lens-2]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = len(test_accuracies)+1\n",
    "plt.plot(range(1, lens), test_accuracies, color='red', linestyle='--', label='accuracies')\n",
    "plt.plot(range(1, lens), test_precisions, color='blue', linestyle='-.', label='precisions')\n",
    "plt.plot(range(1, lens), test_recalls, color='green', linestyle=':', label='recalls')\n",
    "plt.plot(range(1, lens), test_F1_scores, color='yellow', linestyle='-', label='F1_scores')\n",
    "plt.legend()\n",
    "\n",
    "print(f'测试集准确度: {100*test_accuracies[lens-2]}%')\n",
    "print(f'测试集精确度: {100*test_precisions[lens-2]}%')\n",
    "print(f'测试集召回率: {100*test_recalls[lens-2]}%')\n",
    "print(f'测试集F1值: {100*test_F1_scores[lens-2]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        outputs = model(inputs.to(device))\n",
    "        _, predicted = torch.max(outputs.cpu(), dim=1)\n",
    "        labels = labels.cpu()\n",
    "        tp = torch.sum((labels.reshape(-1) == 0) & (predicted == 0)).item()\n",
    "        tn = torch.sum((labels.reshape(-1) == 1) & (predicted == 1)).item()\n",
    "        fp = torch.sum((labels.reshape(-1) == 1) & (predicted == 0)).item()\n",
    "        fn = torch.sum((labels.reshape(-1) == 0) & (predicted == 1)).item()\n",
    "accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "precision = tp/(tp+fp) if ((tp+fp)!=0) else 0\n",
    "recall = tp/(tp+fn) if ((tp+fn)!=0) else 0\n",
    "print(f'测试集准确率: {100*accuracy}%')\n",
    "print(f'测试集精确率: {100*precision}%')\n",
    "print(f'测试集召回率: {100*recall}%')\n",
    "print(f'测试集F1值: {(2*precision*recall/(precision+recall)) if ((precision+recall)!=0) else 0}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        outputs = model(inputs.to(device))\n",
    "        _, predicted = torch.max(outputs.cpu(), dim=1)\n",
    "        for i in range(len(predicted)):\n",
    "            print(f'predict:{predicted[i]}, label:{labels[i]}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), './mymodel/ResNet18/lr=0.0005.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
