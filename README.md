目前来说ResNet18网络效果最佳，在测试集上准确率100%，精确率100%，召回率100%，F1值为1。  
这一结果很不正常，初步推断是由于训练集与测试集由同一组视频数据中切分而来，导致待处理图像相似度极高。存在很大的过拟合可能性，需要进一步使用其他视频生成测试集以检验。  
densenet121的情况略差于ResNet18，准确率95.5%，精确率95.7%，召回率95.3%，F1值: 0.9548。但考虑到这一网络仅使用了一个epoch进行训练，不好判断其是否劣于ResNet18。  
vgg11的效果很差，基本可以放弃这一网络。  
另外，几个网络的训练时间各有差异，ResNet18:1m30s一个epoch(5000条测试数据)，densenet121:17m一个epoch，vgg11:13m一个epoch。以上训练均在RTX3050上进行。  
————————————————————————————————————————————————
目前已经完全放弃了其余两个模型，转入使用ResNet18进行训练。  
## 重新规范了一下数据  
# 将数据集分为了三个部分，train，test与finaltest  
model1由train作为训练集，test和finaltest作为测试集分别测试两次，训练的情况记录在graphs中，两次测试分别由static1和static2体现。同时model1训练出了两个版本，分别由数据库中两次不同的随机选择作为训练集得到，效果差异较大。  
model2由train+0.3\*test作为训练集，即将test中数据的三成放入训练集，剩下七成仍用于测试，以便查看模型能否成功学习test的特征。同样地model2也使用了0.7\*test与finaltest分别做了两次测试。  
model3由train+test作为训练集，finaltest作为测试集。  
# 初步测试情况分析  
model1和model2在test和0.7\*test上的表现都很不错，而且model2没有明显强于model1，这可能是因为test中的图片数据特征与train中特征较为相似。另外model1、2、3在使用finaltest进行测试时表现均不理想。
# 改进
考虑到分析中的问题，我选择将test与finaltest进行对换。model4的训练与测试与model3一致，model5的训练与测试与model2一致，在这两个模型上再次对原来的test进行测试，均有较好的效果。
